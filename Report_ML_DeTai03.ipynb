{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report_ML_CuoiKy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKbbCmKNNAnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bước 1: Khai báo thư viện\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whAD0xE7Yzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "#Bước 2: Đọc dữ liệu\n",
        "train = pd.read_csv('drive/My Drive/Dataset/train.csv')\n",
        "test = pd.read_csv('drive/My Drive/Dataset/test.csv')\n",
        "test_label = pd.read_csv('drive/My Drive/Dataset/test_labels.csv')\n",
        "\n",
        "train_text = train['comment_text']\n",
        "test_text = test['comment_text']\n",
        "\n",
        "print(train_text.head()) \n",
        "print(test_text.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQgCz5kv7ihn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bước 3: Trích chọn đặc trưng\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english', \n",
        "    ngram_range=(1, 1),\n",
        "    max_features=10000)\n",
        "\n",
        "word_vectorizer.fit(train_text)\n",
        "train_word_features = word_vectorizer.transform(train_text)\n",
        "test_word_features = word_vectorizer.transform(test_text)\n",
        "\n",
        "X_train = train_word_features # bien doc lap cua tap train\n",
        "X_test = test_word_features # bien doc lap cua tap test\n",
        "\n",
        "y_train = train[class_names]  # bien phu thuoc cua tap train\n",
        "y_test = test_label[class_names] # bien phu thuoc cua tap test\n",
        "\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "955nl35o7mWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bước 4: Xây dựng model + đánh giá\n",
        "scores = []\n",
        "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
        "for class_name in class_names:\n",
        "    train_target = train[class_name] \n",
        "    classifier = LogisticRegression(C=0.1, solver='sag')\n",
        "\n",
        "    cv_score = np.mean(cross_val_score(classifier, X_train, train_target, cv=3, scoring='roc_auc')) \n",
        "    scores.append(cv_score)\n",
        "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
        "    \n",
        "    classifier.fit(X_train, train_target)\n",
        "    submission[class_name] = classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print('Total CV score is {}'.format(np.mean(scores)))\n",
        "\n",
        "print(submission[class_names])\n",
        "\n",
        "labels = []\n",
        "for data in submission.values:\n",
        "    # print(data[1:6])\n",
        "    labels.append(class_names[np.argmax(data[1:6], axis=0)])\n",
        "\n",
        "submission['label'] = labels\n",
        "print(submission)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}